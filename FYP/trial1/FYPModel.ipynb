{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoders.interleaved import read_pcap\n",
    "from utils.matlab import db\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "import glob\n",
    "from numpy import inf\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \".\"\n",
    "dataset_dir = os.path.join(\"data\")\n",
    "test_dir = os.path.join(\"generated/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 100\n",
    "ALL_ACTIVITIES = [\"static\", \"standing\", \"walking\", \"falling\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFromDat(inputFile, windowSize = FS, step = 50):\n",
    "#     print(int((csi_data.nsamples-1)*(100/average_sample_rate)+1))\n",
    "    \n",
    "    csi_data = read_pcap(inputFile)\n",
    "    csi = csi_data.csi\n",
    "    \n",
    "    \n",
    "    first_timestamp = float(csi_data.timestamps[0])\n",
    "    last_timestamp = float(csi_data.timestamps[-1])\n",
    "    final_timestamp = last_timestamp-first_timestamp\n",
    "    average_sample_rate = csi_data.nsamples/final_timestamp\n",
    "    \n",
    "    interp_func=interp1d(csi_data.timestamps, csi_data.csi, kind='linear', axis=0, fill_value=\"extrapolate\")\n",
    "    t_new = np.linspace(first_timestamp, last_timestamp, (csi_data.nsamples-1)*int((100/average_sample_rate)+1))\n",
    "    csi_interp = interp_func(t_new)\n",
    "    csi=csi_interp\n",
    "    \n",
    "    csi = db(np.abs(csi))\n",
    "    finalData = csi[:, :, 0]\n",
    "    finalData = np.transpose(finalData)\n",
    "    \n",
    "    new_average_sample_rate = len(csi_interp)/final_timestamp\n",
    "    \n",
    "    if new_average_sample_rate > FS:\n",
    "        downsample_factor = int(new_average_sample_rate/FS)\n",
    "        csi = csi[::downsample_factor]\n",
    "    index = 0\n",
    "    positiveInput = []\n",
    "    \n",
    "    while index + windowSize <= csi.shape[0]:\n",
    "        curFeature = np.zeros((1, windowSize, 256))\n",
    "        curFeature[0] = csi[index:index+windowSize, :].reshape(100,256)\n",
    "        positiveInput.append(curFeature)\n",
    "        index += step\n",
    "    try:\n",
    "        positiveInput = np.concatenate(positiveInput, axis = 0)\n",
    "    except ValueError as e:\n",
    "        positiveInput = np.zeros((1, windowSize, 256))\n",
    "    positiveInput[positiveInput == -inf] = 0\n",
    "    \n",
    "    return positiveInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadByActivityLabel(directory, activity, activities=ALL_ACTIVITIES, windowSize=FS, step = 50, downsample=1):\n",
    "    activity = activity.lower()\n",
    "    if activity not in activities:\n",
    "        print(\"invalid activity: \" + activity)\n",
    "    \n",
    "    dataPathPattern = os.path.join(directory,\"{}*.pcap\".format(activity))\n",
    "    inputFiles = sorted(glob.glob(dataPathPattern, recursive =True))\n",
    "    inputWindows = []\n",
    "    index = 0\n",
    "    for inputFile in inputFiles:\n",
    "        index += 1\n",
    "        csiOutput = loadFromDat(inputFile, windowSize = windowSize, step=step)\n",
    "        if csiOutput is not None:\n",
    "            inputWindows.append(csiOutput)\n",
    "    inputArray = np.concatenate(inputWindows, axis = 0)\n",
    "    outputLabels = np.zeros((inputArray.shape[0], len(activities)))\n",
    "    outputLabels[:, activities.index(activity)] = 1\n",
    "    return inputArray, outputLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataForActivities(directory, activities=ALL_ACTIVITIES, windowSize=100, step=50, downsample=1):\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "    for activity in activities:\n",
    "        print(activity)\n",
    "        inputArray, outputLabels = loadByActivityLabel(directory, activity, activities, windowSize=windowSize, step=step, downsample=downsample)\n",
    "        x_all.append(inputArray)\n",
    "        y_all.append(outputLabels)\n",
    "    x_all = np.concatenate(x_all, axis=0)\n",
    "    y_all = np.concatenate(y_all, axis=0)\n",
    "    return (x_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_all, y_all = loadDataForActivities(dataset_dir, downsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[75.82117487, 91.1968139 , 42.14419939, ..., 24.4870632 ,\n",
       "          23.97940009, 17.63427994],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 25.13374666,\n",
       "          18.82639991, 23.98065317],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 25.95279419,\n",
       "          15.27814445, 23.73498563],\n",
       "         ...,\n",
       "         [75.82117487, 91.18616539, 42.14419939, ..., 24.09829638,\n",
       "          20.2568525 , 20.38573453],\n",
       "         [75.82117487, 91.19448347, 42.14419939, ..., 27.89504509,\n",
       "          29.00928825, 22.21924811],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 27.52979228,\n",
       "          27.65363008, 10.51237856]],\n",
       " \n",
       "        [[75.82117487, 91.1968139 , 42.14419939, ..., 14.76296322,\n",
       "          15.05162086, 15.90466465],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 21.79406852,\n",
       "          12.90583814,  6.44155676],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 22.47093636,\n",
       "          -1.78505337, 10.7315378 ],\n",
       "         ...,\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 16.13510665,\n",
       "          20.97791257, 18.88112592],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 20.97930441,\n",
       "          24.99119238, 18.41497335],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 15.92481179,\n",
       "          25.61219306, 22.83090038]],\n",
       " \n",
       "        [[75.82117487, 91.1968139 , 42.14419939, ..., 22.40417253,\n",
       "          23.77547445, 17.12401013],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 18.0255944 ,\n",
       "          22.59137094, 14.78709788],\n",
       "         [75.82117487, 91.19142942, 42.14419939, ..., 25.93229568,\n",
       "          24.5171462 ,  8.95397592],\n",
       "         ...,\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 12.84427063,\n",
       "          26.3094485 , 14.45832885],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 19.30709067,\n",
       "          26.58115924, 15.0053414 ],\n",
       "         [75.82117487, 91.1968139 , 42.14419939, ..., 23.59524859,\n",
       "          26.87178047, 15.72369611]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[75.82117487, 91.06631452, 42.14419939, ..., 14.62397998,\n",
       "           0.        , 16.98970004],\n",
       "         [75.82117487, 91.06631452, 42.14419939, ..., 11.41763098,\n",
       "           8.82807451, 13.86020512],\n",
       "         [75.82117487, 91.05845019, 42.14419939, ..., 16.0888489 ,\n",
       "          13.92731552,  9.29750567],\n",
       "         ...,\n",
       "         [75.82117487, 91.1020832 , 42.14419939, ..., 24.06610815,\n",
       "          19.79947997, 19.64413103],\n",
       "         [75.82117487, 91.11040668, 42.14419939, ..., 22.49767363,\n",
       "          19.77495005, 21.10800498],\n",
       "         [75.82117487, 91.12058766, 42.14419939, ..., 19.08228923,\n",
       "          20.53650674, 22.52644483]],\n",
       " \n",
       "        [[75.82117487, 91.10476487, 42.14419939, ..., 18.58359495,\n",
       "          18.8699314 , 17.50737479],\n",
       "         [75.82117487, 91.11235961, 42.14419939, ..., 17.76279596,\n",
       "          24.69241505, 18.66112548],\n",
       "         [75.82117487, 91.11766573, 42.14419939, ..., 15.38406491,\n",
       "          26.71586305, 18.47830241],\n",
       "         ...,\n",
       "         [75.82117487, 91.18259482, 42.14419939, ..., 21.46083444,\n",
       "          17.29662132, 16.68904269],\n",
       "         [75.82117487, 91.17507637, 42.14419939, ..., 20.88748599,\n",
       "          12.40242633, 12.88640925],\n",
       "         [76.09022325, 91.18536947, 42.14419939, ..., 21.32912012,\n",
       "          16.39198411, 11.47134808]],\n",
       " \n",
       "        [[75.82117487, 91.14304765, 42.14419939, ..., 16.75028103,\n",
       "          19.84911031, 16.46484284],\n",
       "         [75.82117487, 91.1657134 , 42.14419939, ..., 27.06974109,\n",
       "          23.24266076, 13.87516862],\n",
       "         [75.82117487, 91.18858164, 42.14419939, ..., 31.66398239,\n",
       "          26.59314436, 20.76298614],\n",
       "         ...,\n",
       "         [75.82117487, 91.05928503, 42.14419939, ...,  7.99575711,\n",
       "          14.8753149 ,  6.89991384],\n",
       "         [75.82117487, 91.07582427, 42.14419939, ...,  4.90110117,\n",
       "          14.19624628, 13.01925974],\n",
       "         [75.82117487, 91.09233784, 42.14419939, ..., 10.04711236,\n",
       "          15.46241316, 16.42093069]]]),\n",
       " array([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadDataForActivities(dataset_dir, downsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_all, y_all, stratify=y_all, test_size = 0.3, random_state=42)\n",
    "print(len(x_val[0][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 100\n",
    "\n",
    "f1s = []\n",
    "confs = []\n",
    "y_val_total = np.array([])\n",
    "y_pred_total = np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "# model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Bidirectional(LSTM(units=200, return_sequences=False)))\n",
    "# model.add(Bidirectional(LSTM(units=200, return_sequences=False)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 16s 1s/step - loss: 1.3261 - accuracy: 0.4058 - val_loss: 1.0839 - val_accuracy: 0.6139\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 3s 620ms/step - loss: 1.0489 - accuracy: 0.6239 - val_loss: 1.0341 - val_accuracy: 0.4713\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 3s 625ms/step - loss: 0.9559 - accuracy: 0.6290 - val_loss: 0.9498 - val_accuracy: 0.5901\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 3s 595ms/step - loss: 1.0129 - accuracy: 0.5671 - val_loss: 0.9298 - val_accuracy: 0.6119\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 3s 634ms/step - loss: 0.8274 - accuracy: 0.7224 - val_loss: 0.8356 - val_accuracy: 0.7228\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 3s 591ms/step - loss: 0.7992 - accuracy: 0.7088 - val_loss: 0.8467 - val_accuracy: 0.6673\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 3s 666ms/step - loss: 0.7573 - accuracy: 0.7767 - val_loss: 0.7039 - val_accuracy: 0.8198\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 3s 579ms/step - loss: 0.6777 - accuracy: 0.7980 - val_loss: 0.9544 - val_accuracy: 0.5406\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 3s 550ms/step - loss: 0.7556 - accuracy: 0.7250 - val_loss: 0.6257 - val_accuracy: 0.7941\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 3s 591ms/step - loss: 0.6705 - accuracy: 0.7419 - val_loss: 0.6433 - val_accuracy: 0.8277\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 3s 549ms/step - loss: 0.6501 - accuracy: 0.8065 - val_loss: 0.6452 - val_accuracy: 0.7267\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 3s 519ms/step - loss: 0.6123 - accuracy: 0.7521 - val_loss: 0.5842 - val_accuracy: 0.8218\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 3s 579ms/step - loss: 0.5408 - accuracy: 0.8081 - val_loss: 0.7025 - val_accuracy: 0.7960\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 3s 563ms/step - loss: 0.5586 - accuracy: 0.8430 - val_loss: 0.5248 - val_accuracy: 0.8594\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 3s 576ms/step - loss: 0.6341 - accuracy: 0.7462 - val_loss: 0.8549 - val_accuracy: 0.6653\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 3s 583ms/step - loss: 0.5891 - accuracy: 0.8014 - val_loss: 0.4933 - val_accuracy: 0.8535\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 3s 595ms/step - loss: 0.5424 - accuracy: 0.7810 - val_loss: 0.7013 - val_accuracy: 0.7050\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 3s 580ms/step - loss: 0.4844 - accuracy: 0.8582 - val_loss: 0.4938 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 3s 568ms/step - loss: 0.5382 - accuracy: 0.7479 - val_loss: 0.4433 - val_accuracy: 0.8376\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 3s 573ms/step - loss: 0.3990 - accuracy: 0.8803 - val_loss: 0.7981 - val_accuracy: 0.7129\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 3s 595ms/step - loss: 0.5747 - accuracy: 0.7869 - val_loss: 0.4599 - val_accuracy: 0.8673\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 3s 598ms/step - loss: 0.4858 - accuracy: 0.8124 - val_loss: 0.4811 - val_accuracy: 0.8059\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 3s 563ms/step - loss: 0.4811 - accuracy: 0.7835 - val_loss: 0.5155 - val_accuracy: 0.8614\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 3s 577ms/step - loss: 0.4171 - accuracy: 0.8710 - val_loss: 0.5192 - val_accuracy: 0.8040\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 3s 595ms/step - loss: 0.4843 - accuracy: 0.7674 - val_loss: 0.5273 - val_accuracy: 0.7545\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 3s 580ms/step - loss: 0.3947 - accuracy: 0.8820 - val_loss: 0.3479 - val_accuracy: 0.9426\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 3s 580ms/step - loss: 0.5354 - accuracy: 0.7742 - val_loss: 0.6245 - val_accuracy: 0.7188\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 3s 567ms/step - loss: 0.4351 - accuracy: 0.8625 - val_loss: 0.5998 - val_accuracy: 0.7723\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 3s 561ms/step - loss: 0.5012 - accuracy: 0.7564 - val_loss: 0.4676 - val_accuracy: 0.8356\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 3s 599ms/step - loss: 0.4232 - accuracy: 0.8591 - val_loss: 0.4966 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 3s 567ms/step - loss: 0.4542 - accuracy: 0.7869 - val_loss: 0.4389 - val_accuracy: 0.8554\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 3s 560ms/step - loss: 0.4085 - accuracy: 0.8404 - val_loss: 0.6202 - val_accuracy: 0.7802\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 3s 557ms/step - loss: 0.4021 - accuracy: 0.8735 - val_loss: 0.3409 - val_accuracy: 0.9406\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 3s 571ms/step - loss: 0.4993 - accuracy: 0.7954 - val_loss: 0.4500 - val_accuracy: 0.8020\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 3s 592ms/step - loss: 0.3600 - accuracy: 0.8718 - val_loss: 0.4254 - val_accuracy: 0.8673\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 3s 551ms/step - loss: 0.4614 - accuracy: 0.7912 - val_loss: 0.5500 - val_accuracy: 0.8099\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 3s 556ms/step - loss: 0.3638 - accuracy: 0.8964 - val_loss: 0.4088 - val_accuracy: 0.8238\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 3s 578ms/step - loss: 0.4473 - accuracy: 0.8192 - val_loss: 0.4280 - val_accuracy: 0.8079\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 3s 559ms/step - loss: 0.3337 - accuracy: 0.8905 - val_loss: 0.4231 - val_accuracy: 0.8059\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 3s 582ms/step - loss: 0.4318 - accuracy: 0.8200 - val_loss: 0.5316 - val_accuracy: 0.7941\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 3s 568ms/step - loss: 0.3985 - accuracy: 0.8616 - val_loss: 0.2979 - val_accuracy: 0.9564\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 3s 568ms/step - loss: 0.4665 - accuracy: 0.7903 - val_loss: 0.3387 - val_accuracy: 0.8257\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 3s 581ms/step - loss: 0.4084 - accuracy: 0.8065 - val_loss: 0.4446 - val_accuracy: 0.7901\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 3s 575ms/step - loss: 0.3575 - accuracy: 0.8786 - val_loss: 0.3451 - val_accuracy: 0.9406\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 3s 590ms/step - loss: 0.3964 - accuracy: 0.8370 - val_loss: 0.4042 - val_accuracy: 0.8079\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 3s 577ms/step - loss: 0.3731 - accuracy: 0.8404 - val_loss: 0.4147 - val_accuracy: 0.8891\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 3s 593ms/step - loss: 0.3310 - accuracy: 0.8964 - val_loss: 0.5967 - val_accuracy: 0.7842\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 3s 582ms/step - loss: 0.4290 - accuracy: 0.8192 - val_loss: 0.3841 - val_accuracy: 0.8356\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 3s 644ms/step - loss: 0.3367 - accuracy: 0.8540 - val_loss: 0.7162 - val_accuracy: 0.7485\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 3s 524ms/step - loss: 0.3598 - accuracy: 0.8973 - val_loss: 0.2948 - val_accuracy: 0.9208\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 3s 552ms/step - loss: 0.4530 - accuracy: 0.8065 - val_loss: 0.4255 - val_accuracy: 0.8158\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 3s 557ms/step - loss: 0.3405 - accuracy: 0.8769 - val_loss: 0.3711 - val_accuracy: 0.8950\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 3s 573ms/step - loss: 0.3905 - accuracy: 0.8506 - val_loss: 0.4036 - val_accuracy: 0.8099\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 3s 599ms/step - loss: 0.3952 - accuracy: 0.8141 - val_loss: 0.3290 - val_accuracy: 0.8931\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 3s 552ms/step - loss: 0.3115 - accuracy: 0.8871 - val_loss: 0.4638 - val_accuracy: 0.7960\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 3s 587ms/step - loss: 0.3811 - accuracy: 0.8285 - val_loss: 0.3626 - val_accuracy: 0.9168\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 3s 587ms/step - loss: 0.3472 - accuracy: 0.8718 - val_loss: 0.3688 - val_accuracy: 0.8198\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 3s 571ms/step - loss: 0.3489 - accuracy: 0.8497 - val_loss: 0.3794 - val_accuracy: 0.9129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "5/5 [==============================] - 3s 566ms/step - loss: 0.3715 - accuracy: 0.8472 - val_loss: 0.3226 - val_accuracy: 0.8317\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 3s 568ms/step - loss: 0.3657 - accuracy: 0.8328 - val_loss: 0.3826 - val_accuracy: 0.8376\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 3s 541ms/step - loss: 0.3934 - accuracy: 0.8514 - val_loss: 0.3469 - val_accuracy: 0.8297\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 3s 583ms/step - loss: 0.3708 - accuracy: 0.8217 - val_loss: 0.3406 - val_accuracy: 0.8515\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 3s 599ms/step - loss: 0.2464 - accuracy: 0.9372 - val_loss: 0.2637 - val_accuracy: 0.8931\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 3s 552ms/step - loss: 0.4109 - accuracy: 0.8158 - val_loss: 0.3545 - val_accuracy: 0.8752\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 3s 569ms/step - loss: 0.3498 - accuracy: 0.8633 - val_loss: 0.2701 - val_accuracy: 0.9129\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 3s 581ms/step - loss: 0.3021 - accuracy: 0.8803 - val_loss: 0.3468 - val_accuracy: 0.9406\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 3s 585ms/step - loss: 0.3679 - accuracy: 0.8480 - val_loss: 0.2989 - val_accuracy: 0.8396\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 3s 622ms/step - loss: 0.3462 - accuracy: 0.8277 - val_loss: 0.3221 - val_accuracy: 0.9168\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 3s 602ms/step - loss: 0.2940 - accuracy: 0.9092 - val_loss: 0.3706 - val_accuracy: 0.8198\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 3s 598ms/step - loss: 0.3821 - accuracy: 0.8065 - val_loss: 0.2764 - val_accuracy: 0.9109\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 3s 593ms/step - loss: 0.2156 - accuracy: 0.9380 - val_loss: 0.4724 - val_accuracy: 0.7050\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 3s 587ms/step - loss: 0.4367 - accuracy: 0.8370 - val_loss: 0.3803 - val_accuracy: 0.8099\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 3s 573ms/step - loss: 0.3694 - accuracy: 0.7954 - val_loss: 0.3626 - val_accuracy: 0.8713\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 3s 586ms/step - loss: 0.3203 - accuracy: 0.8744 - val_loss: 0.3975 - val_accuracy: 0.8158\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 3s 558ms/step - loss: 0.3506 - accuracy: 0.8311 - val_loss: 0.2818 - val_accuracy: 0.8713\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 3s 600ms/step - loss: 0.2410 - accuracy: 0.9219 - val_loss: 0.3225 - val_accuracy: 0.8752\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 3s 585ms/step - loss: 0.3287 - accuracy: 0.8693 - val_loss: 0.4295 - val_accuracy: 0.8139\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 3s 563ms/step - loss: 0.3457 - accuracy: 0.8463 - val_loss: 0.3610 - val_accuracy: 0.9188\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 3s 589ms/step - loss: 0.3341 - accuracy: 0.8803 - val_loss: 0.3460 - val_accuracy: 0.8218\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 3s 572ms/step - loss: 0.3494 - accuracy: 0.8141 - val_loss: 0.3049 - val_accuracy: 0.9050\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 3s 612ms/step - loss: 0.3435 - accuracy: 0.8642 - val_loss: 0.3479 - val_accuracy: 0.8178\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 3s 609ms/step - loss: 0.2832 - accuracy: 0.8829 - val_loss: 0.2300 - val_accuracy: 0.9624\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 3s 544ms/step - loss: 0.3291 - accuracy: 0.8633 - val_loss: 0.2479 - val_accuracy: 0.8832\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 3s 586ms/step - loss: 0.3164 - accuracy: 0.8404 - val_loss: 0.3103 - val_accuracy: 0.8772\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 3s 567ms/step - loss: 0.2225 - accuracy: 0.9465 - val_loss: 0.2069 - val_accuracy: 0.9485\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 3s 583ms/step - loss: 0.3717 - accuracy: 0.8294 - val_loss: 0.3413 - val_accuracy: 0.8812\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 3s 575ms/step - loss: 0.2532 - accuracy: 0.9363 - val_loss: 0.2501 - val_accuracy: 0.8832\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 3s 545ms/step - loss: 0.4037 - accuracy: 0.7997 - val_loss: 0.3707 - val_accuracy: 0.8455\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 3s 582ms/step - loss: 0.3203 - accuracy: 0.8778 - val_loss: 0.3789 - val_accuracy: 0.8139\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 3s 605ms/step - loss: 0.3006 - accuracy: 0.8803 - val_loss: 0.2747 - val_accuracy: 0.9584\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 3s 544ms/step - loss: 0.3265 - accuracy: 0.8650 - val_loss: 0.3401 - val_accuracy: 0.8297\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 3s 570ms/step - loss: 0.2836 - accuracy: 0.8710 - val_loss: 0.2369 - val_accuracy: 0.9584\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 3s 533ms/step - loss: 0.3412 - accuracy: 0.8514 - val_loss: 0.2710 - val_accuracy: 0.8733\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 3s 526ms/step - loss: 0.2272 - accuracy: 0.9261 - val_loss: 0.2496 - val_accuracy: 0.9525\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 3s 603ms/step - loss: 0.3490 - accuracy: 0.8531 - val_loss: 0.2772 - val_accuracy: 0.8653\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 3s 568ms/step - loss: 0.2973 - accuracy: 0.8684 - val_loss: 0.2707 - val_accuracy: 0.9267\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 3s 597ms/step - loss: 0.2514 - accuracy: 0.8964 - val_loss: 0.6006 - val_accuracy: 0.8020\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 3s 591ms/step - loss: 0.3247 - accuracy: 0.8990 - val_loss: 0.2606 - val_accuracy: 0.9347\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 3s 566ms/step - loss: 0.2829 - accuracy: 0.8862 - val_loss: 0.4022 - val_accuracy: 0.8119\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 3s 594ms/step - loss: 0.2882 - accuracy: 0.8846 - val_loss: 0.2475 - val_accuracy: 0.9465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2be864ea230>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256, epochs=100, shuffle=False, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 41ms/step\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print(len(x_val[50][99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_single = np.argmax(y_val, axis=1)\n",
    "y_pred_single = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[161   0   3   0]\n",
      " [  0  70  16   0]\n",
      " [  5   3 158   0]\n",
      " [  0   0   0  89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      static       0.97      0.98      0.98       164\n",
      "    standing       0.96      0.81      0.88        86\n",
      "     walking       0.89      0.95      0.92       166\n",
      "     falling       1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           0.95       505\n",
      "   macro avg       0.96      0.94      0.94       505\n",
      "weighted avg       0.95      0.95      0.95       505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val_single, y_pred_single))\n",
    "print(classification_report(y_val_single, y_pred_single, target_names=[\"static\", \"standing\", \"walking\", \"falling\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_network.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './generated/data/falling.pcap'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_all \u001b[38;5;241m=\u001b[39m loadFromDat(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/falling.pcap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [4], line 4\u001b[0m, in \u001b[0;36mloadFromDat\u001b[1;34m(inputFile, windowSize, step)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadFromDat\u001b[39m(inputFile, windowSize \u001b[38;5;241m=\u001b[39m FS, step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     print(int((csi_data.nsamples-1)*(100/average_sample_rate)+1))\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     csi_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_pcap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     csi \u001b[38;5;241m=\u001b[39m csi_data\u001b[38;5;241m.\u001b[39mcsi\n\u001b[0;32m      8\u001b[0m     first_timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(csi_data\u001b[38;5;241m.\u001b[39mtimestamps[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\PycharmProjects\\FYP\\trial1\\decoders\\interleaved.py:231\u001b[0m, in \u001b[0;36mread_pcap\u001b[1;34m(pcap_filepath, bandwidth, nsamples_max)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_pcap\u001b[39m(pcap_filepath, bandwidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, nsamples_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m        Reads CSI samples from\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m        a pcap file. A SampleSet\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m        default, but you can also set them explicitly.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m     pcap_filesize \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcap_filepath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_size\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pcap_filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pcapfile:\n\u001b[0;32m    233\u001b[0m         fc \u001b[38;5;241m=\u001b[39m pcapfile\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './generated/data/falling.pcap'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# x_all = loadFromDat(f\"./{test_dir}/falling.pcap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
